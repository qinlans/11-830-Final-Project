{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = '../data/davidson/'\n",
    "path = '../data/zeerak_naacl/'\n",
    "train = pd.read_csv('{}train.csv'.format(path), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "none_msk = train['none'] == 1\n",
    "off_msk = ~ none_msk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_counts(df):\n",
    "    return Counter(' '.join(df['tweet']).split(' '))\n",
    "\n",
    "def normalize(df):\n",
    "    df['offensive_norm'] = df['offensive'] / sum(df['offensive'])\n",
    "    df['none_norm'] = df['none'] / sum(df['none'])\n",
    "    return df\n",
    "\n",
    "def llr(wc1, wc2):\n",
    "    return -np.log(wc1 / wc2)\n",
    "\n",
    "def compute_llr(df):\n",
    "    llr_list = []\n",
    "    for wc1, wc2 in tqdm_notebook(zip(df['offensive_norm'], df['none_norm'])):\n",
    "        llr_list.append(nll(wc1, wc2))\n",
    "    print(len(nll_list))\n",
    "    df['log_ratio'] = nll_list\n",
    "    return df.sort_values('log_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "off_wc = get_word_counts(train[off_msk])\n",
    "non_wc = get_word_counts(train[none_msk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wc_df = pd.DataFrame(columns=['offensive', 'none'])\n",
    "\n",
    "# Add counts from each class\n",
    "for w, c in tqdm_notebook(off_wc.items()):\n",
    "    wc_df.loc[w, 'offensive'] = c\n",
    "for w, c in tqdm_notebook(non_wc.items()):\n",
    "    wc_df.loc[w, 'none'] = c\n",
    "    \n",
    "wc_df.fillna(1, inplace=True)\n",
    "wc_df['total'] = wc_df['offensive'] + wc_df['none']\n",
    "\n",
    "wc_df = normalize(wc_df)\n",
    "wc_df = compute_nll(wc_df)\n",
    "\n",
    "wc_df['weighted_ratio'] = wc_df['log_ratio'] * wc_df['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc_df.sort_values('weighted_ratio', ascending=True)[:100].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude_terms = ['sexist', 'islam', 'women', 'muslims', 'notsexist',\n",
    "               'mohammed', 'female', 'muslims', 'girls', 'men', 'woman',\n",
    "               'man', 'prophet', 'religion', 'jews', 'quran', 'girl',\n",
    "               'slave', 'hatred', 'feminists', 'feminist', 'females',\n",
    "               'feminism', 'hate', 'rape', 'womenagainstfeminism',\n",
    "               'questionsformen', 'slavery', 'murdering', 'bigotry',\n",
    "               'equal', 'slaves', 'christians', 'hindus', 'israel',\n",
    "               'terrorist', 'islamic', 'barbarity', 'blondes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the exclusion terms\n",
    "\n",
    "Along with the original hatebase slurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "fname = '{}hatebase_slurs.txt'.format(path)\n",
    "slurs = pd.read_csv(fname, header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_slurs = np.concatenate([exclude_terms, slurs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_slurs_df = pd.DataFrame(new_slurs)\n",
    "new_slurs_df.to_csv('{}hatebase+zeerak_exclude_slurs.txt'.format(path),\n",
    "                    index=None, header=None, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
