{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = '../data/davidson/'\n",
    "path = '../data/zeerak_naacl/'\n",
    "# path = '../data/wiki_talk/'\n",
    "# debug = pd.read_csv('{}debug.csv'.format(path), encoding='utf-8')\n",
    "train = pd.read_csv('{}train.csv'.format(path), encoding='utf-8')\n",
    "dev = pd.read_csv('{}dev.csv'.format(path), encoding='utf-8')\n",
    "test = pd.read_csv('{}test.csv'.format(path), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate_speech', 'none'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fix labels for davidson\n",
    "new_train_labels = ['neither' if l == 'offensive_language' else l\n",
    "                    for l in train['label']]\n",
    "new_test_labels = ['neither' if l == 'offensive_language' else l\n",
    "                    for l in test['label']]\n",
    "train['label'] = new_train_labels\n",
    "test['label'] = new_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix labels for zeerak\n",
    "new_train_labels = [l if l == 'none' else 'hate_speech'\n",
    "                    for l in train['label']]\n",
    "new_test_labels = [l if l == 'none' else 'hate_speech'\n",
    "                    for l in test['label']]\n",
    "train['label'] = new_train_labels\n",
    "test['label'] = new_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['tweet'])\n",
    "X_train = vectorizer.transform(train['tweet'])\n",
    "y_train = train['label'].values\n",
    "\n",
    "X_test = vectorizer.transform(test['tweet'])\n",
    "y_test = test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "\tPrecision: 0.93\n",
      "\tRecall: 0.93\n",
      "\tF1-Score: 0.93\n",
      "\tAccuracy: 0.93\n",
      "Training\n",
      "\tPrecision: 0.84\n",
      "\tRecall: 0.84\n",
      "\tF1-Score: 0.84\n",
      "\tAccuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "p, r, f1, s = precision_recall_fscore_support(y_train, y_train_pred, average='weighted')\n",
    "acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training\\n\\tPrecision: {p:.2f}\\n\\tRecall: {r:.2f}\\n\\tF1-Score: {f1:.2f}\\n\\tAccuracy: {acc:.2f}\")\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_test_pred, average='weighted')\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Training\\n\\tPrecision: {p:.2f}\\n\\tRecall: {r:.2f}\\n\\tF1-Score: {f1:.2f}\\n\\tAccuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(columns=['word', 'coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccf41b2eee2497eabd5afaaf2aad3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "coef_df['coef'] = clf.coef_[0]\n",
    "for w, i in tqdm_notebook(vectorizer.vocabulary_.items()):\n",
    "    coef_df.loc[i, 'word'] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_df.sort_values(by='coef', ascending=True, inplace=True)\n",
    "coef_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Davidson output\n",
    "#coef_df.to_csv('../output/davidson_log_reg_coef.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zeerak output\n",
    "coef_df.to_csv('../output/zeerak_log_reg_coef.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_path = '../data/davidson/'\n",
    "z_path = '../data/zeerak_naacl/'\n",
    "o2_path = '../output/davidson_2way_gradrev_0.5/'\n",
    "o3_path = '../output/davidson-zeerak_davidson_2018-04-25T10-55/'\n",
    "\n",
    "d_test = pd.read_csv(f'{d_path}test.csv', encoding='utf-8')\n",
    "d_pred = pd.read_pickle(f'{o2_path}test_preds.pkl')\n",
    "\n",
    "z_test = pd.read_csv(f'{z_path}test.csv', encoding='utf-8')\n",
    "z_pred = pd.read_pickle(f'{o3_path}test_preds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_test['pred'] = d_pred\n",
    "d_test = d_test[['tweet', 'label', 'pred']].copy()\n",
    "d_test.loc[:, 'label'] = [1 if l == 'hate_speech' else 0 for l in d_test['label']]\n",
    "d_test['correct'] = [*map(int, d_test['label'] == d_test['pred'])]\n",
    "\n",
    "z_test['pred'] = z_pred\n",
    "z_test = z_test[['tweet', 'label', 'pred']].copy()\n",
    "z_test.loc[:, 'label'] = [0 if l == 'none' else 1 for l in z_test['label']]\n",
    "z_test['correct'] = [*map(int, z_test['label'] == z_test['pred'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2318, 1: 146})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(d_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davidson 2-way:\n",
      "\ttn: 2246\n",
      "\tfp: 72\n",
      "\tfn: 94\n",
      "\ttp: 52\n",
      "Davidson-Zeerak:\n",
      "\ttn: 990\n",
      "\tfp: 95\n",
      "\tfn: 426\n",
      "\ttp: 59\n"
     ]
    }
   ],
   "source": [
    "print(\"Davidson 2-way:\")\n",
    "tn, fp, fn, tp = confusion_matrix(d_test.label, d_test.pred).ravel()\n",
    "print(f\"\\ttn: {tn}\\n\\tfp: {fp}\\n\\tfn: {fn}\\n\\ttp: {tp}\")\n",
    "print(\"Davidson-Zeerak:\")\n",
    "tn, fp, fn, tp = confusion_matrix(z_test.label, z_test.pred).ravel()\n",
    "print(f\"\\ttn: {tn}\\n\\tfp: {fp}\\n\\tfn: {fn}\\n\\ttp: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull out 10 examples of fp and fn for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_error_samples(df):\n",
    "    \"\"\"Return two df's that are fp and fn.\"\"\"\n",
    "    fp_msk = (df['correct'] == 0) & (df['pred'] == 1)\n",
    "    fp_ex = df[fp_msk].copy()\n",
    "    \n",
    "    fn_msk = (df['correct'] == 0) & (df['pred'] == 0)\n",
    "    fn_ex = df[fn_msk].copy()\n",
    "    \n",
    "    return fp_ex, fn_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_fp, d_fn = get_error_samples(d_test)\n",
    "z_fp, z_fn = get_error_samples(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = '../output/error_analysis/'\n",
    "d_fname = '{}davidson_grad_rev_{}.csv'\n",
    "z_fname = '{}davidson-zeerak_{}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_fp.to_csv(d_fname.format(out_path, 'fp'), encoding='utf-8', index=False)\n",
    "d_fn.to_csv(d_fname.format(out_path, 'fn'), encoding='utf-8', index=False)\n",
    "z_fp.to_csv(z_fname.format(out_path, 'fp'), encoding='utf-8', index=False)\n",
    "z_fn.to_csv(z_fname.format(out_path, 'fn'), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'every spic cop in # losangeles has raped or has thought about raping a white woman that s why those half_breeds get jobs as pigs'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fn.loc[662, 'tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<MENTION> 1 2 3 4 how many niggers are in my store i knowwwww your stealing ðŸ˜‚ðŸ˜‚ðŸ˜‚ that vine still be having me weak'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fp.loc[2161].tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1501    # mkr the fat south africans are feeling hopeful\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = ['africa' in t for t in z_fp.tweet]\n",
    "z_fp[msk].tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
